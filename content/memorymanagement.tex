% !TEX root = ../document.tex
\section{Memory Management}
\label{sec:MemoryManagement}
Damit Anwendungen von der CPU ausgeführt werden können, muss das Betriebssystem der Anwendung einen Bereich des Hauptspeichers zuteilen. In diesem Speicherbereich befinden sich bei einem Rechner mit der Von-Neumann-Architektur einerseits die Befehle, sowie die Daten der Anwendung. Diese Zuteilung und Verwaltung des Speichers sind Aufgaben des Memory Managements und werden von dem Memory Manager des Betriebssystems durchgeführt. Der Begriff Speicherverwaltung umfasst im Prinzip auch die Verwaltung der Cache-Speicher in der CPU, da diese jedoch häufig durch die Hardware direkt verwaltet wird, liegt die Fokus dieser Ausarbeitung auf der Verwaltung des Hauptspeichers.

Anschließend werden die einige Modelle der Speicherabstraktion vorgestellt, erläutert und ihre Vor- und Nachteile benannt.

\subsection{Ohne Speicherabstraktion}
\label{subsec:OhneSpeicherabstraktion}
Das einfachste Modell der Speicherverwaltung besitzt keine Speicherabstraktion. Das heißt, dass Prozesse direkt auf die Speicheradressen des Hauptspeichers zugreifen.(978-3868942705, S.239) Der maximale Speicherverbrauch eines Prozesses ist in diesem Modell durch den physikalischen Hauptspeicher begrenzt, da ohne Speicherverwaltung ausschließlich der gesamte Prozess als ein Ganzes in den Hauptspeicher geladen werden kann.(978-3868942705, S.239) Angewendet wird dieses Modell beispielsweise in Embedded Systems, da die komplexität der Implementierung sehr gering ist.(978-3868942705, S.242) Jedoch birgt der unkontrollierte Zugriff der Anwendungen auf den physikalischen Speicher auch ein Risiko, da die Anwendung die Daten und Befehle des Betriebssystem überschreiben kann.(978-3868942705, S.241) Außerdem ist zu erwähnen, dass ohne Swapping des Hauptspeichers eine simultane  Ausführung von mehreren Anwendungen nicht möglich ist.(978-3868942705, S.241) Swapping bezeichnet hierbei die Auslagerung des gesamten Speichers einer Anwendung aus dem Hauptspeicher auf ein anderes Medium wie beispielsweise einer Festplatte.(978-3868942705, S.241) Das Thema Swapping wird im Folge der Ausarbeitung noch weiter erläutert.

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{ohneSpeicherabstraktion.png}{0.3}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}


\subsection{Adressr\"{a}ume}
\label{subsec:Adressraeume}
Ein Modell das die simultane Ausführung von Prozessen ermöglicht ist die Speicherabstraktion Adressräume. Die Idee dieses Modells ist die Allokation eines Speicherbereiches zu einem Prozess und der dynamischen Relokation der Speicherbereiche.(978-3868942705, S.244) Einem Prozess wird beispielsweise der Adressbereich 128 bis 192 zugewiesen und einem anderen Prozess der Bereich 192 bis 224. Nun besteht das Problem, dass der Prozess wissen müsste an welche Stelle im Hauptspeicher geladen wird, damit Zugriffe und Sprünge der Anwendung auf die richtigen Speicheradressen verweisen.(978-3868942705, S.244) Das Problem löst das Adressraum Modell mit von Basis- und Limitregistern.(978-3868942705, S.244) Die Entwickler benutzten bei der Programmierung einer Anwendung einen Adressraum von 0 bis maximale Speichergröße.(978-3868942705, S.244) Sobald nun der Prozess ausgeführt wird, wird die Startadresse des Prozess in den Basisregister und die Größe des Prozesses in das Limitregister der CPU geschrieben.(978-3868942705, S.244) Bei der Ausführung einer Operation wird nun zu jeder Adresse der Basisregister addiert.(978-3868942705, S.244) Das Ergebnis dieser Addition bildet die physikalische Adresse im Hauptspeicher ab.(978-3868942705, S.244) Um Beispielsweise die physikalische Adresse des Befehls der Anwendung 1 aus der Abbildung XXX zu bekommen, muss die Startadresse (in der CPU befindet sich die Adresse im Basisregister) der Anwendung mit der Adresse aus dem Adressraum der Anwendung addiert werden. Falls die angegebene Adresse grösser als der Wert des Limitregisters ist, erfolgt ein Betriebssystem Interrupt und das Betriebssystem beendet der Prozess.(978-3868942705, S.244) Jedoch besteht auch bei der Implementierung von Adressräumen mithilfe von Basis- und Limitregistern immernoch das Problem, dass der maximale Speicherbedarf eines Prozesses von dem physikalischen Speicher begrenzt ist.(978-3868942705, S.244) Eine Ausführung einer Anwendung oder mehrere simultan laufende Anwendungen die in Summe einen höheren Hauptspeicherverbrauch haben als der physikalische Speicher es zulässt ist nicht möglich.(978-3868942705, S.244)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{adressraeume.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsection{Swapping}
\label{subsec:Swapping}
Eine Strategie die es erlaubt mehrere Prozesse trotz fehlendem Hauptspeicherplatzes auszuführen ist das Swapping.(978-3868942705, S.245) Es bezeichnet die Auslagerung von Prozessen von dem Hauptspeicher auf die Festplatte, um Hauptspeicherplatz zu gewinnen.(978-3868942705, S.245) Beispielsweise soll in Abbildung XXX der Prozess 4 ausgeführt werden. Derzeit ist der Hauptspeicher mit den Daten und Befehle des Betriebssystem sowie der Prozesse 1, 2 und 3 vollständig gefüllt. Demnach kann der Prozess 4 nicht ohne ein Auslagerung eines oder mehrerer Prozesse geladen werden. Deswegen werden zunächst die Prozesse 2 und 3 auf die Festplatte ausgelagert, anschließend der Prozess in den freien Speicherbereich kopiert und die Befehle des Prozesses 4 ausgeführt. Durch die Ein- und Auslagerung von Prozessen können Lücken im Speicher entstehen, welche mit der Technik Speicherverdichtung zu großen Lücken zusammengefasst werden können, in dem alle Prozesse so weit wie möglich nach unten geschoben werden.(978-3868942705, S.246) Da Prozesse während der Laufzeit wachsen können kann es passieren, dass Prozesse in andere größere Speicherlücken umgelagert werden.(978-3868942705, S.247) Falls keine passende Lücke vorhanden ist, kommt es notfalls zur Auslagerung anderer Prozesse.(978-3868942705, S.247) Diese Relokationen können mit hilfe eines Puffers für jeden Prozess in einigen Fällen verhindert werden. Der Wachstum eines Prozesses kann einerseits Aufgrund wachsender Daten und andererseits aufgrund wachsender Anzahl von Rücksprungadressen entstehen.(978-3868942705, S.247) Falls ausschließlich dynamische Daten vorhanden sind, sollten der Puffer oberhalb angesetzt werden, sodass die Daten nach oben hin wachsen können.(978-3868942705, S.247) Falls beide Wachstums-Varianten beachtet werden müssen, sollte ein Stack mit mit lokalen Variablen und Rücksprungadressen im oberen Teil des Speicherbereiches und die dynamischen Daten im unteren Teil alloziert werden.(978-3868942705, S.247) Der freien Speicher befindet sich in dieser Variante mittig.

Die Kombination aus Adressräumen und Swapping erlaubt es mehrere Prozesse, die gemeinsam nicht in den Hauptspeicher passen, parallel auszuführen. Jedoch kann das Betriebssystem auch mit der Abstraktion keine Prozesse ausführen, deren Speicherverbrauch größer als der physikalische Speicher ist.

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{swapping.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsection{Verwaltung von freiem Speicher}
\label{subsec:VerwaltungFreiemSpeicher}
Um den freien physikalischen Speicher möglichst effizient auszunutzen, gibt es verschiedene Arten der Speicherverwaltung. Diese Zielen darauf ab, möglichst wenige und kleine Lücken im Speicher zu lassen, um den Anteil an ungenutztem Speicher so klein zu halten wie es möglich ist.

Vier der wichtigsten Optionen sind die Anordnung als Stack, eine verkettete Liste, eine Bitmap und das Buddy System. In XINU werden von diesen der Stack standardmäßig und die verkettete Liste auf Anfrage genutzt. (978-1-4987-1244-6 S.157)

\subsubsection{Stack}
Bei der Nutzung von Stacks werden die möglichen Speicheradressen als Stapel gespeichert. Sollte eine Adresse benötigt werden. So wird die oberste Adresse vom Stapel gezogen und verwendet. Umgekehrt wird eine Adresse, die frei geworden ist, wieder oben auf den Stapel gelegt. (978-1-4987-1244-6 S.165)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{stack.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsubsection{Verkettete Liste}
Wenn der Speicher mit Hilfe einer verketteten Liste organisiert werden soll, so werden in dieser Liste jeweils ein Zeiger auf den Startpunkt und die Länge des Blocks gepflegt. Diese Liste kann nun auf der Suche nach einem passenden Speicherplatz durchlaufen werden. 

Dabei gibt es mehrere Möglichkeiten:

First fit: Die Liste wird von Anfang an durchlaufen und der erste Block, der groß genug ist, wird genutzt.(978-3868942705, S.250/251)

Next fit: Die Liste hat einen Iterator. Die Suche nach passenden Speicherblöcken wird nicht immer vom Anfang der Liste aus durchgeführt sondern vom letzten Ort, an dem sich der Iterator befand.(978-3868942705, S.250/251)

Best fit: Die Liste wird komplett durchlaufen. Danach wird der Block genutzt, dessen größe der des zu speichernden Elementes am nächsten ist, ohne diese zu unterschreiten. Dadurch bleibt der geringstmögliche Speicher ungenutzt.(978-3868942705, S.250/251)

Worst fit: Es wird die Liste komplett durchlaufen. Nun wird jedoch der größte Speicherblock gesucht, damit die nach dem Speichern übrige Speicherkapazität des Blocks groß genug ist, um noch einen nutzbaren Block zu bilden.(978-3868942705, S.250/251)

Quick fit: Lücken ähnlicher Größen werden in verschiedenen Listen gespeichert. Ein Speicherbereich wird dann über diese Liste zugewiesen.(978-3868942705, S.250/251)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{verkettete-liste.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsubsection{Bitmap}
Bei der Speicherverwaltung über Bitmaps wird jedem Speicherblock in einer Bitmap ein Bit zugeordnet. Dieses zeigt dann an, ob der betreffende Speicher im Moment belegt ist, oder nicht. (978-3868942705, S.248/249)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{bitmap.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsubsection{Buddy-System}
Das Buddy-System teilt den Speicher in verschiedene Blöcke von mehreren festgelegten Größen auf, meist als Zweierpotenzen. Sollte dann ein Element abgespeichert werden, so wird ein Block der bestmöglichen vorhandenen Größe genutzt, um möglichst wenig Speicher ungenutzt gelassen.

Wenn nun allerdings sämtliche Blöcke einer Speichergröße belegt sind, diese Größe aber benötigt wird, so ist es möglich, einen Block der nächsthöheren Größe zu halbieren. Die beiden dadurch entstandenen kleineren Speicherblöcke werden Buddies genannt. (ISBN 978-3-662-54099-2 S.126)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{buddies.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsection{Virtueller Speicher}
\label{subsec:VirtuelleAdressraeume}
Das Problem des begrenzten Speicherplatzes wird durch den sogenannten virtuellen Speicher gelöst. Dessen Idee ist es den Adressraum eines Prozesses in sogenannte Seiten(Pages) aufzuteilen.(978-3868942705, S.252) Falls der Prozess einen Befehl einer nicht im Speicher vorhandenen Seite ausführen möchte, wird ein Betriebssystem Interrupt ausgelöst.(978-3868942705, S.252) Daraufhin lädt das Betriebssystem die benötigte Page nach und führt den fehlgeschlagenen Befehl erneut aus.(978-3868942705, S.252) Demnach muss nicht der gesamte Adressraum eines Prozess im Hauptspeicher vorhanden sein und gleichzeitig können auch Anwendungen ausgeführt werden, die größer sind als der physikalische Hauptspeicher.

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{VirtuellerSpeicher.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

\subsubsection{Paging}
Seiten haben eine feste Speichergröße die oft die Größe des Seitenrahmen entspricht.(978-3868942705, S.253) Seitenrahmen(page frame) sind die entsprechenden physikalischen Einheiten des RAMs.(978-3868942705, S.253) Die Adressen der Anwendung werden auch als virtuelle Adressen bezeichnet und bilden in Summe den virtuellen Adressraum des Prozesses.(978-3868942705, S.253) In einem System ohne Speicherabstraktion würden diese Adressen direkt angesprochen werden. Virtuelle Adressen werden von der CPU zunächst an die MMU(Memory Management Unit) geschickt, die diese Adresse dann mithilfe einer Seitentabelle zu der entsprechenden physikalischen Adresse umwandelt.(978-3868942705, S.253) Da die Seiten eine einheitliche Größe haben, kann mit hilfe der virtuellen Adresse erkannt werden, welche Seite für die Operation benötigt wird.(978-3868942705, S.253) Ist angeforderte Seite nicht im Speicher vorhanden, wirft die MMU ein Interrupt.(978-3868942705, S.254/255) Das Betriebssystem kopiert daraufhin die gewünschte Seite in den Hauptspeicher, aktualisiert die Seitentabelle und führt den fehlgeschlagenen Befehl erneut aus.(978-3868942705, S.254/255) 

\subsubsection{Paging Table}
Die virtuelle Adresse besteht aus einer virtuellen Seitennummer und einem Offset für die Adresse in einer Seite.(978-3868942705, S.257) Als Index der Tabelle wird die Seitennummer genutzt zu der dann die entsprechende Seitenrahmennummer, das Present-/Absent-Bit und weitere Steuerungs-Flags gespeichert werden.(978-3868942705, S.257) Das Present-/Absent-Bit gibt an ob die Seite sich aktuell im Speicher befindet oder nicht.(978-3868942705, S.255) Die weiteren Flags können beispielsweise Zugriffsrechte auf die Seitenrahmen repräsentieren und somit Zugriffe auf gesperrte Seitenrahmen verhindern.(978-3868942705, S.258) Die Seitennummer der virtuellen Adresse wird mit der Seitenrahmennummer ersetzt und ergibt damit die physikalische Adresse.(978-3868942705, S.257)
Da bei der Übersetzung einer virtuellen Adresse durch die MMU zu vielen Zwischenschritten kommt und somit die Performance beeinträchtigt, wurde der TLB(Translation Lookside Buffer) entwickelt.(978-3868942705, S.260/261) Der TLB ist häufig ein Teil der MMU und ermöglicht es Übersetzungen ohne Zugriff auf die Seitentabelle durchzuführen.(978-3868942705, S.260/261) Der Puffer enthält Einträge über die Seiten, deren Informationen enthalten grundsätzlich die gleichen Informationen wie die der Seitentabelle.(978-3868942705, S.260/261) Zusätzlich enthalten die Einträge noch die virtuelle Seite und ein Gültigkeits-Flag, welches die Aktivität der Seite repräsentiert.(978-3868942705, S.260/261) Wird nun eine virtuelle Adresse in die MMU zur Übersetzung eingegeben, vergleicht die MMU parallel alle Einträge mit der virtuelle Adresse.(978-3868942705, S.260/261) Wird ein Eintrag im TLB gefunden, kann die virtuelle Adresse ohne Zugriff auf die Seitentabelle übersetzt werden.(978-3868942705, S.260/261) Andernfalls lädt die MMU den entsprechenden Eintrag aus der Seitentabelle und ersetzt diesen mit einen älteren Eintrag aus dem TLB.(978-3868942705, S.260/261) Der nächste Zugriff auf die Seite ist danach wieder ohne einen Selektion der Seitentabelle möglich.(978-3868942705, S.260/261)

\subsubsection{Seitenersetzungsalgorithmen}
Bei jedem Seitenfehler muss das Betriebssystem, falls kein Platz im Hauptspeicher vorhanden ist, eine Seite auslagern um Platz für die gewünschte Seite zu machen.(978-3868942705, S.267) Hierbei gibt es mehrere Algorithmen die entscheiden welche Seite ausgelagert werden soll.(978-3868942705, S.267) Der optimale Algorithmus wäre einer der Überprüft von welchen der derzeit eingelagerten Seiten die wenigsten noch auszuführenden Befehle enthält beziehungsweise die längste Wartezeit bis zur nächsten Ausführung eines Befehles besitzt.(978-3868942705, S.268)  Dieser Algorithmus ist jedoch in der Realität nicht realisierbar, da das Betriebssystem nicht weiß auf welche Seite demnächst zugegriffen wird.(978-3868942705, S.268) 
Der Not-Recently-Used-Algorithmus(NRU) nutzt die zwei Statusbits R und M.(978-3868942705, S.269) Das R-Bit wird gesetzt sobald ein Schreib- oder Lesezugriff auf eine Seite stattfindet.(978-3868942705, S.269)  Wiederum das M-Bit gesetzt wird falls Daten in der Seite modifiziert wurden.(978-3868942705, S.269)  Mithilfe eines Timer-Interrupts setzt das Betriebssystem zyklisch die R-Bits zurück.(978-3868942705, S.269) Falls nun ein Seitenfehler auftritt und eine Seite ausgelagert werden muss klassifiziert das Betriebssystem alle vorhandenen Seiten in vier Klassen.(978-3868942705, S.270)  Klasse 0 sind Seiten die nicht referenziert und nicht modifiziert wurden. Klasse 1 sind Seiten die nicht referenziert und modifiziert wurden. Klasse 2 sind Seiten die referenziert und nicht modifiziert wurden. Klasse 4 sind Seiten die referenziert und modifiziert wurden.(978-3868942705, S.270) Das Betriebssystem entfernt mit dem NRU-Algorithmus nun eine zufällige Seite aus der niedrigsten nicht leeren Klasse.(978-3868942705, S.270)
Bei dem First-In-First-Out-Algorithmus(FIFO) verwaltet das Betriebssystem die im Speicher vorhandenen Seiten als verkettete Liste. Die erste Seite der Liste wird entfernt und die neue Seite wird am Ende der Liste angefügt.(978-3868942705, S.270)
Der Second-Chance-Algorithmus funktioniert auch nach dem FIFO Prinzip mit dem Unterschied, dass bei der Auslagerung einer Seite überprüft wird ob die Seite das R-Bit gesetzt hat.(978-3868942705, S.271) Wurde die Seite referenziert, wird das R-Bit zurückgesetzt, die Seite wie eine neue Seite an das Ende der Kette verschoben und anschließend nach einer neuen Seite zum auslagern gesucht.(978-3868942705, S.271)
Der Least-Recently-Used-Algorithmus(LRU) folgt der Annahme, dass eine Seite die in den letzten Operationen häufig gebraucht wurde, sehr wahrscheinlich in den folgenden Operationen ebenso benötigt wird.(978-3868942705, S.272) Daraus lässt sich schliessen, dass lang ungenutzte Seiten auch länger benötigt bleiben und demnach ausgelagert werden können.(978-3868942705, S.272) Die Realisierung des LRU-Algorithmus ist mithilfe von verketteter Listen möglich.(978-3868942705, S.272) Jedoch werden wenige Rechner nach diesem Schema realisiert, da die Aktualisierung der Liste einen hohen Rechenaufwand benötigt.(978-3868942705, S.272) Eine Alternative zu diesem ist der durch Software implementierte Not-Frequently-Used-Algorithmus, bei dem bei jedem Timerinterrupt ein Softwarezähler pro Seite mitzählt, ob das R-Bit gesetzt wurde oder nicht.(978-3868942705, S.273)

\subsection{Segmentierung}
Das Paging erlaubt es mehrere Anwendungen auszuführen welche einzeln oder in Summe  größer sind als der physikalische Speicher des Systems. Jedoch ermöglichen viele Programmiersprachen eine dynamische Allokation von Speicher. In dem normalen Paging-Modell könnte der Speicherbereich für beispielsweise einer Tabelle volllaufen und der Entwickler der Software müsste ein solches Problem abfangen.(978-3868942705, S.302) Die Speicherabstaktion Segmentierung löst dieses Problem in dem es den Anwendungsspeicher in Einheiten mit freier Größe, den sogenannten Segmenten, unterteilt.(978-3868942705, S.303)  Jedes Segment besitzt seinen eigenen Adressraum mit Zugriffsrechten, welcher wachsen und schrumpfen kann.(978-3868942705, S.303) Eine virtuelle Adresse besteht hierbei aus der Kombination der Segmentnummer und einer Adresse innerhalb des Segmentes.(978-3868942705, S.304) Die Adressübersetzung der Segmentierung funktioniert analog zur der Adressübersetzung des Paging. Jedoch kann es bei dieser Variante zu einer großen Anzahl von kleinen Lücken im Speicher kommen, die für benötigte Segmente zu klein sind.(978-3868942705, S.306) Diese Verschwendung des Speicherplatzes wird als externe Fragmentierung bezeichnet und kann durch die Speicherverdichtung verhindert werden.(978-3868942705, S.306)

\begin{figure}[htb]
	\centering
	\includegraphicsKeepAspectRatio{Segmentierung.png}{0.8}
	\caption{Hauptspeicher ohne Speicherabstraktion}
\end{figure}

In der Praxis gibt es kaum Systeme die Segmentierung als Speicherabstraktion nutzen. Häufiger ist die Kombination aus Segmentierung und Paging, jedoch sind trotzdem die meisten Systeme mit der Speicherabstraktion Paging implementiert.

\subsection{Buffer Pools}
\label{subsec:BufferPools}
Das Betriebssystem Xinu nutzt keine virtuellen Adressräume, sondern Buffer Pools.(978-1-4987-1243-9, S.176) Hierbei wird der physikalische Speicher in Bereiche, den Buffer Pools, aufgeteilt.(978-1-4987-1243-9, S.176) Jeder Buffer Pool hat gleiche Anzahl von Speicherblocks mit derselben Größe.(978-1-4987-1243-9, S.176) Nach der Erstellung eines Buffer Pools wird der physikalische Speicher alloziert und kann nicht mehr vergrössert oder verkleinert werden.(978-1-4987-1243-9, S.177) Die Informationen des Buffer Pools werden in einer Systemtabelle buftab gespeichert.(978-1-4987-1243-9, S.177) Dessen Einträge aus der Buffer Pool-ID, der Buffer-Größe und einem Zeiger auf die Buffer-Liste bestehen.(978-1-4987-1243-9, S.177)  Diese Tabelle wird im Boot-Prozess des Betriebssystems erstellt.(978-1-4987-1243-9, S.183)
Ein Prozess kann mit der Funktion mkbuffpool einen neuen Buffer Pool anlegen.(978-1-4987-1243-9, S.181) Hierbei fordert die Funktion die Anzahl der zu erstellenden Buffer und deren Größe.(978-1-4987-1243-9, S.181) Zunächst werden die Argumente der Funktion überprüft, falls die Werte nicht realisierbar sind folgt eine Fehlermeldung.(978-1-4987-1243-9, S.181) Andernfalls berechnet die Funktion die gesamte Größe des Buffer Pool und alloziert den Speicher.(978-1-4987-1243-9, S.181) Darauf erstellt die Funktion einen Eintrag in der Systemtabelle buftab.(978-1-4987-1243-9, S.181) Nachdem der Eintrag erstellt wurde iteriert die Funktion über die Anzahl der Buffers und erstellt einen Eintrag in der Buffer-Liste des Buffer Pools.(978-1-4987-1243-9, S.181) Zuletzt gibt die Funktion die ID des Buffer Pools an den aufrufenden Prozess zurück.(978-1-4987-1243-9, S.181)

listing mkbuffpool.c

Nachdem der Prozess nun einen Buffer Pool erstellt hat, kann dieser mit der Buffer Pool ID einen Buffer anfordern.(978-1-4987-1243-9, S.178) Dies geschieht über die Funktion getbuf mit der Buffer Pool ID als Argument.(978-1-4987-1243-9, S.178) getbuf funktioniert Synchron, dass heißt falls kein freier Buffer im Pool vorhanden ist, wartet das System solange bis ein Buffer freigegeben wird, gibt die Adresse des Buffers an den aufrufenden Prozess zurück und entfernt den Buffer aus der verketteten Liste des Buffer Pools.(978-1-4987-1243-9, S.178)  Die Funktion liefert jedoch nicht direkt die erste Adresse des Buffers, sondern speichert in dieser die Pool ID und gibt anschließend die darauf folgende Adresse zurück.(978-1-4987-1243-9, S.179) Dieses Verfahren dient zur Identifizierung des Pools.(978-1-4987-1243-9, S.179) 

listing getbuf.c

Nachdem der Prozess seine Aufgaben bewältigt hat, muss dieser die allozierten Buffer wieder an den Pool zurückgegeben.(978-1-4987-1243-9, S.179) Dies ist mit der Funktion freebuf möglich.(978-1-4987-1243-9, S.179) Als Argument verlangt die Funktion den Zeiger auf den Buffer.(978-1-4987-1243-9, S.179) Mit diesem Zeiger liest die Funktion zunächst die Pool ID aus, um anschließend den Buffer wieder in der verketteten Liste des Buffer Pools einzufügen.(978-1-4987-1243-9, S.180) Zuletzt wird noch dem System mitgeteilt, dass wieder ein freier Buffer im Pool vorhanden ist.(978-1-4987-1243-9, S.180)

listing freebuf.c

Xinu verwendet ein rudimentäres Modell zur Verwaltung des Hauptspeichers. Die Implementierung besitzt keine Schutzmechanismen auf fremde Speicheradressen und bietet auch keine Möglichkeit Anwendungen die mehr Speicherplatz benötigen als der physikalische Speicher es zulässt auszuführen. Jedoch muss beachtet werden, dass das Betriebssystem für Lernzwecke entwickelt wurde und den lernenden auf einfache Art und Weise die Funktionsweise der Betriebssysteme erläutern soll.

